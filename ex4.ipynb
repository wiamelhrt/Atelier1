{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e74407",
   "metadata": {},
   "source": [
    "# Structured data learning with Wide, Deep, and Cross networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4024b4",
   "metadata": {},
   "source": [
    "## This illustration shows how to classify structured data using the two modeling techniques: models Wide & Deep models Deep & Cross\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493f320",
   "metadata": {},
   "source": [
    "## The Covertype dataset from the UCI Machine Learning Repository is used in this example. Predicting the kind of forest cover from geographic factors is the task. There are 506,011 cases in the dataset with 12 input features—10 numerical and 2 categorical. Each instance is put into one of seven classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3192e63",
   "metadata": {},
   "source": [
    "### import all libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6abfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15205434",
   "metadata": {},
   "source": [
    "### Download the data from the url and load it into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec27af66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279  ...   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225  ...   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121  ...   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211  ...   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172  ...   0   0   0   0   \n",
       "\n",
       "   49  50  51  52  53  54  \n",
       "0   0   0   0   0   0   5  \n",
       "1   0   0   0   0   0   5  \n",
       "2   0   0   0   0   0   2  \n",
       "3   0   0   0   0   0   2  \n",
       "4   0   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    ")\n",
    "raw_data = pd.read_csv(data_url, header=None)\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf27f6b",
   "metadata": {},
   "source": [
    "### The dataset contains two binary-encoded category features. We'll change the representation of this dataset to the standard representation, in which each categorical feature is represented by a single integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c01b217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>2596</td>\n",
       "      <td>2590</td>\n",
       "      <td>2804</td>\n",
       "      <td>2785</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>268</td>\n",
       "      <td>242</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>510</td>\n",
       "      <td>390</td>\n",
       "      <td>3180</td>\n",
       "      <td>3090</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>232</td>\n",
       "      <td>235</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>6279</td>\n",
       "      <td>6225</td>\n",
       "      <td>6121</td>\n",
       "      <td>6211</td>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type</th>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_12</td>\n",
       "      <td>soil_type_30</td>\n",
       "      <td>soil_type_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0             1             2  \\\n",
       "Elevation                                   2596          2590          2804   \n",
       "Aspect                                        51            56           139   \n",
       "Slope                                          3             2             9   \n",
       "Horizontal_Distance_To_Hydrology             258           212           268   \n",
       "Vertical_Distance_To_Hydrology                 0            -6            65   \n",
       "Horizontal_Distance_To_Roadways              510           390          3180   \n",
       "Hillshade_9am                                221           220           234   \n",
       "Hillshade_Noon                               232           235           238   \n",
       "Hillshade_3pm                                148           151           135   \n",
       "Horizontal_Distance_To_Fire_Points          6279          6225          6121   \n",
       "Wilderness_Area                      area_type_1   area_type_1   area_type_1   \n",
       "Soil_Type                           soil_type_29  soil_type_29  soil_type_12   \n",
       "Cover_Type                                     4             4             1   \n",
       "\n",
       "                                               3             4  \n",
       "Elevation                                   2785          2595  \n",
       "Aspect                                       155            45  \n",
       "Slope                                         18             2  \n",
       "Horizontal_Distance_To_Hydrology             242           153  \n",
       "Vertical_Distance_To_Hydrology               118            -1  \n",
       "Horizontal_Distance_To_Roadways             3090           391  \n",
       "Hillshade_9am                                238           220  \n",
       "Hillshade_Noon                               238           234  \n",
       "Hillshade_3pm                                122           150  \n",
       "Horizontal_Distance_To_Fire_Points          6211          6172  \n",
       "Wilderness_Area                      area_type_1   area_type_1  \n",
       "Soil_Type                           soil_type_30  soil_type_29  \n",
       "Cover_Type                                     1             4  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_values = [f\"soil_type_{idx+1}\" for idx in range(40)]\n",
    "wilderness_area_values = [f\"area_type_{idx+1}\" for idx in range(4)]\n",
    "\n",
    "soil_type = raw_data.loc[:, 14:53].apply(\n",
    "    lambda x: soil_type_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "wilderness_area = raw_data.loc[:, 10:13].apply(\n",
    "    lambda x: wilderness_area_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area\",\n",
    "    \"Soil_Type\",\n",
    "    \"Cover_Type\",\n",
    "]\n",
    "\n",
    "data = pd.concat(\n",
    "    [raw_data.loc[:, 0:9], wilderness_area, soil_type, raw_data.loc[:, 54]],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "data.columns = CSV_HEADER\n",
    "\n",
    "# Convert the target label indices into a range from 0 to 6 (there are 7 labels in total).\n",
    "data[\"Cover_Type\"] = data[\"Cover_Type\"] - 1\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f810cace",
   "metadata": {},
   "source": [
    "### Split the data into training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5635f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 494005\n",
      "Test split size: 87007\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in data.groupby(\"Cover_Type\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.85\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split size: {len(train_data.index)}\")\n",
    "print(f\"Test split size: {len(test_data.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e5b502",
   "metadata": {},
   "source": [
    "### the training and test data should then be kept in separate CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc90fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3b648",
   "metadata": {},
   "source": [
    "### we define thedataset's metadata, which will be used for reading, parsing, and encoding the input features according to their kinds after the data has been divided into input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9e7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = \"Cover_Type\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Aspect\",\n",
    "    \"Elevation\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Slope\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"Soil_Type\": list(data[\"Soil_Type\"].unique()),\n",
    "    \"Wilderness_Area\": list(data[\"Wilderness_Area\"].unique()),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cd59c0",
   "metadata": {},
   "source": [
    "### define an input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9699913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2e5ea",
   "metadata": {},
   "source": [
    "### Using a model as a starting point, configure the parameters and carry out the procedure to perform the training and evaluation experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5023f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269c9f3",
   "metadata": {},
   "source": [
    "### Create model inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdf196ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88997dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\" if use_embedding else \"binary\",\n",
    "            )\n",
    "            if use_embedding:\n",
    "                # Convert the string input values into integer indices.\n",
    "                encoded_feature = lookup(inputs[feature_name])\n",
    "                embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "                # Create an embedding layer with the specified dimensions.\n",
    "                embedding = layers.Embedding(\n",
    "                    input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "                )\n",
    "                # Convert the index values to embedding representations.\n",
    "                encoded_feature = embedding(encoded_feature)\n",
    "            else:\n",
    "                # Convert the string input values into a one hot encoding.\n",
    "                encoded_feature = lookup(tf.expand_dims(inputs[feature_name], -1))\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b040d7",
   "metadata": {},
   "source": [
    "### Let's construct a multi-layer feed-forward network for the first experiment, with the categorical features one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95b39cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py:2453: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decf942c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1865/1865 [==============================] - 17s 8ms/step - loss: 0.7620 - sparse_categorical_accuracy: 0.6826\n",
      "Epoch 2/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.6617 - sparse_categorical_accuracy: 0.7145\n",
      "Epoch 3/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.6309 - sparse_categorical_accuracy: 0.7272\n",
      "Epoch 4/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.6126 - sparse_categorical_accuracy: 0.7356\n",
      "Epoch 5/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.6013 - sparse_categorical_accuracy: 0.7409\n",
      "Epoch 6/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5941 - sparse_categorical_accuracy: 0.7447\n",
      "Epoch 7/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5879 - sparse_categorical_accuracy: 0.7475\n",
      "Epoch 8/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5830 - sparse_categorical_accuracy: 0.7497\n",
      "Epoch 9/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5786 - sparse_categorical_accuracy: 0.7510\n",
      "Epoch 10/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5746 - sparse_categorical_accuracy: 0.7526\n",
      "Epoch 11/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5705 - sparse_categorical_accuracy: 0.7541\n",
      "Epoch 12/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.7556\n",
      "Epoch 13/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5642 - sparse_categorical_accuracy: 0.7567\n",
      "Epoch 14/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5629 - sparse_categorical_accuracy: 0.7572\n",
      "Epoch 15/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 16/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5577 - sparse_categorical_accuracy: 0.7595\n",
      "Epoch 17/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5560 - sparse_categorical_accuracy: 0.7601\n",
      "Epoch 18/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5535 - sparse_categorical_accuracy: 0.7614\n",
      "Epoch 19/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.7622\n",
      "Epoch 20/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5501 - sparse_categorical_accuracy: 0.7626\n",
      "Epoch 21/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.7632\n",
      "Epoch 22/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5477 - sparse_categorical_accuracy: 0.7638\n",
      "Epoch 23/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5458 - sparse_categorical_accuracy: 0.7646\n",
      "Epoch 24/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5460 - sparse_categorical_accuracy: 0.7646\n",
      "Epoch 25/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5435 - sparse_categorical_accuracy: 0.7656\n",
      "Epoch 26/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.7661\n",
      "Epoch 27/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7661\n",
      "Epoch 28/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5414 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 29/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.7673\n",
      "Epoch 30/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5396 - sparse_categorical_accuracy: 0.7676\n",
      "Epoch 31/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5395 - sparse_categorical_accuracy: 0.7677\n",
      "Epoch 32/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.7688\n",
      "Epoch 33/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.7684\n",
      "Epoch 34/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7697\n",
      "Epoch 35/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5360 - sparse_categorical_accuracy: 0.7698\n",
      "Epoch 36/50\n",
      "1865/1865 [==============================] - 11s 6ms/step - loss: 0.5352 - sparse_categorical_accuracy: 0.7699\n",
      "Epoch 37/50\n",
      "1865/1865 [==============================] - 8s 5ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7698\n",
      "Epoch 38/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5341 - sparse_categorical_accuracy: 0.7699\n",
      "Epoch 39/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5325 - sparse_categorical_accuracy: 0.7711\n",
      "Epoch 40/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5319 - sparse_categorical_accuracy: 0.7714\n",
      "Epoch 41/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5320 - sparse_categorical_accuracy: 0.7713\n",
      "Epoch 42/50\n",
      "1865/1865 [==============================] - 8s 5ms/step - loss: 0.5311 - sparse_categorical_accuracy: 0.7713\n",
      "Epoch 43/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5319 - sparse_categorical_accuracy: 0.7710\n",
      "Epoch 44/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5307 - sparse_categorical_accuracy: 0.7715\n",
      "Epoch 45/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5303 - sparse_categorical_accuracy: 0.7724\n",
      "Epoch 46/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5292 - sparse_categorical_accuracy: 0.7727\n",
      "Epoch 47/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5295 - sparse_categorical_accuracy: 0.7724\n",
      "Epoch 48/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5289 - sparse_categorical_accuracy: 0.7721\n",
      "Epoch 49/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5278 - sparse_categorical_accuracy: 0.7730\n",
      "Epoch 50/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5280 - sparse_categorical_accuracy: 0.7725\n",
      "Model training finished\n",
      "Test accuracy: 77.29%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8644c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d1d5155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1865/1865 [==============================] - 14s 6ms/step - loss: 0.7250 - sparse_categorical_accuracy: 0.7015\n",
      "Epoch 2/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.6045 - sparse_categorical_accuracy: 0.7383\n",
      "Epoch 3/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5857 - sparse_categorical_accuracy: 0.7463\n",
      "Epoch 4/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5731 - sparse_categorical_accuracy: 0.7527\n",
      "Epoch 5/50\n",
      "1865/1865 [==============================] - 10s 5ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 6/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5564 - sparse_categorical_accuracy: 0.7604\n",
      "Epoch 7/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5514 - sparse_categorical_accuracy: 0.7635\n",
      "Epoch 8/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5463 - sparse_categorical_accuracy: 0.7652\n",
      "Epoch 9/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5421 - sparse_categorical_accuracy: 0.7668\n",
      "Epoch 10/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5385 - sparse_categorical_accuracy: 0.7684\n",
      "Epoch 11/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5356 - sparse_categorical_accuracy: 0.7693\n",
      "Epoch 12/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.7703\n",
      "Epoch 13/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5315 - sparse_categorical_accuracy: 0.7719\n",
      "Epoch 14/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.7732\n",
      "Epoch 15/50\n",
      "1865/1865 [==============================] - 8s 5ms/step - loss: 0.5266 - sparse_categorical_accuracy: 0.7738\n",
      "Epoch 16/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5249 - sparse_categorical_accuracy: 0.7742\n",
      "Epoch 17/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5235 - sparse_categorical_accuracy: 0.7752\n",
      "Epoch 18/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5220 - sparse_categorical_accuracy: 0.7756\n",
      "Epoch 19/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5204 - sparse_categorical_accuracy: 0.7761\n",
      "Epoch 20/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5195 - sparse_categorical_accuracy: 0.7770\n",
      "Epoch 21/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5188 - sparse_categorical_accuracy: 0.7773\n",
      "Epoch 22/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5170 - sparse_categorical_accuracy: 0.7778\n",
      "Epoch 23/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5161 - sparse_categorical_accuracy: 0.7785\n",
      "Epoch 24/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5153 - sparse_categorical_accuracy: 0.7790\n",
      "Epoch 25/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5143 - sparse_categorical_accuracy: 0.7789\n",
      "Epoch 26/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5133 - sparse_categorical_accuracy: 0.7796\n",
      "Epoch 27/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5113 - sparse_categorical_accuracy: 0.7804\n",
      "Epoch 28/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.7808\n",
      "Epoch 29/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5089 - sparse_categorical_accuracy: 0.7813\n",
      "Epoch 30/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5079 - sparse_categorical_accuracy: 0.7818\n",
      "Epoch 31/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5077 - sparse_categorical_accuracy: 0.7820\n",
      "Epoch 32/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5067 - sparse_categorical_accuracy: 0.7831\n",
      "Epoch 33/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5060 - sparse_categorical_accuracy: 0.7835\n",
      "Epoch 34/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.7843\n",
      "Epoch 35/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.7841\n",
      "Epoch 36/50\n",
      "1865/1865 [==============================] - 7s 4ms/step - loss: 0.5037 - sparse_categorical_accuracy: 0.7849\n",
      "Epoch 37/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5019 - sparse_categorical_accuracy: 0.7848\n",
      "Epoch 38/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5020 - sparse_categorical_accuracy: 0.7855\n",
      "Epoch 39/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5016 - sparse_categorical_accuracy: 0.7857\n",
      "Epoch 40/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.5000 - sparse_categorical_accuracy: 0.7861\n",
      "Epoch 41/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.7852\n",
      "Epoch 42/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.7864\n",
      "Epoch 43/50\n",
      "1865/1865 [==============================] - 8s 5ms/step - loss: 0.4991 - sparse_categorical_accuracy: 0.7864\n",
      "Epoch 44/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7865\n",
      "Epoch 45/50\n",
      "1865/1865 [==============================] - 8s 5ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7875\n",
      "Epoch 46/50\n",
      "1865/1865 [==============================] - 9s 5ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7871\n",
      "Epoch 47/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4971 - sparse_categorical_accuracy: 0.7872\n",
      "Epoch 48/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4963 - sparse_categorical_accuracy: 0.7877\n",
      "Epoch 49/50\n",
      "1865/1865 [==============================] - 8s 4ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.7876\n",
      "Epoch 50/50\n",
      "1865/1865 [==============================] - 11s 6ms/step - loss: 0.4957 - sparse_categorical_accuracy: 0.7884\n",
      "Model training finished\n",
      "Test accuracy: 80.78%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c617841",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40093db",
   "metadata": {},
   "source": [
    "###  You can manage categorical features with various encoding strategies, such as one-hot encoding and feature embedding, with ease by using Keras Preprocessing Layers. Additionally, various model topologies, including as wide, deep, and cross networks, offer various benefits in relation to certain dataset features. For the best outcome for your dataset, experiment with utilizing them separately or in combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076c18da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
