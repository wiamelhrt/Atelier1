{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140c6ff7",
   "metadata": {},
   "source": [
    "# Structured data classification from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33e4c1",
   "metadata": {},
   "source": [
    "## This example shows how to classify structured data starting from an unprocessed CSV file. Both numerical and category features are present in our data. To vectorize the categorical features and normalize the numerical features, we will use Keras preprocessing layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795df07",
   "metadata": {},
   "source": [
    "## The Cleveland Clinic Foundation for Heart Disease has donated our dataset. There are 303 rows in the CSV file. Each column lists a characteristic of a patient, and each row includes information about a patient (a sample) (a feature). To determine whether a patient has heart disease, we examine the features (binary classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e92f6",
   "metadata": {},
   "source": [
    "### import all libraries that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a70054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d610fb",
   "metadata": {},
   "source": [
    "### Download the data from the url and load it into a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c4215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c845b8",
   "metadata": {},
   "source": [
    "### For this line we have shape attribute enables us to obtain the shape of a DataFrame in this dataset we have  303 raw and 14 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "070f2265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8a5e4",
   "metadata": {},
   "source": [
    "###  To get the first n rows for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23796d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69e81",
   "metadata": {},
   "source": [
    "### Split the data into training/testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d0add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06040531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde23981",
   "metadata": {},
   "source": [
    "### For our dataset we have input (Age,Sex,CP,...) and for the output 0 or 1 a Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f1aa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=54>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=110>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=214>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=158>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=1.6>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ba2b6",
   "metadata": {},
   "source": [
    "### The batch size is a hyperparameter that defines the number of samples to work through before updating the internal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4c95e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41b86c5",
   "metadata": {},
   "source": [
    "# Feature preprocessing of our dataset with Keras layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7608c97",
   "metadata": {},
   "source": [
    "### we will use IntegerLookup() turns integer categorical values into an encoded representation that can be read by an Embedding layer or Dense layer, and import Normalization that helps to change the range and scale of data thereby bring uniformity to data, and finally we import Stringlookup for translates a set of arbitrary strings into integer output via a table-based vocabulary lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5471facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8342da5",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597e05d0",
   "metadata": {},
   "source": [
    "### For build model step i see how we can encoded Categorical features as integers or string ,with choosing the number of nodes in each hidden layer ,also the best activation function ,Optimizer algorithm and the Regularization technique  appropriate to augment the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d986358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd3fed",
   "metadata": {},
   "source": [
    "### visualize our connectivity graph using graphviz and pydot , graphviz for visualization is a way of representing structural information as diagrams of abstract graphs and networks, and for pydot also  an open source graph visualization software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de7c5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3648ed4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882496ef",
   "metadata": {},
   "source": [
    "### Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5179422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 4s 163ms/step - loss: 0.7887 - accuracy: 0.4711 - val_loss: 0.7255 - val_accuracy: 0.5246\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.7148 - accuracy: 0.5455 - val_loss: 0.6636 - val_accuracy: 0.6066\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6701 - accuracy: 0.6198 - val_loss: 0.6138 - val_accuracy: 0.7049\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6422 - accuracy: 0.6240 - val_loss: 0.5717 - val_accuracy: 0.7213\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5930 - accuracy: 0.6777 - val_loss: 0.5401 - val_accuracy: 0.7541\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5622 - accuracy: 0.7107 - val_loss: 0.5128 - val_accuracy: 0.7869\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5586 - accuracy: 0.7190 - val_loss: 0.4900 - val_accuracy: 0.7541\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5183 - accuracy: 0.7562 - val_loss: 0.4691 - val_accuracy: 0.7705\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.5302 - accuracy: 0.7355 - val_loss: 0.4532 - val_accuracy: 0.7705\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4572 - accuracy: 0.8058 - val_loss: 0.4403 - val_accuracy: 0.7869\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4409 - accuracy: 0.8017 - val_loss: 0.4307 - val_accuracy: 0.8033\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4718 - accuracy: 0.7521 - val_loss: 0.4223 - val_accuracy: 0.8033\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4500 - accuracy: 0.8017 - val_loss: 0.4163 - val_accuracy: 0.8033\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4294 - accuracy: 0.7975 - val_loss: 0.4100 - val_accuracy: 0.8033\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4197 - accuracy: 0.8182 - val_loss: 0.4055 - val_accuracy: 0.8033\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4192 - accuracy: 0.7727 - val_loss: 0.4029 - val_accuracy: 0.8361\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4233 - accuracy: 0.8017 - val_loss: 0.3997 - val_accuracy: 0.8361\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8017 - val_loss: 0.3974 - val_accuracy: 0.8361\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8430 - val_loss: 0.3951 - val_accuracy: 0.8361\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8099 - val_loss: 0.3933 - val_accuracy: 0.8361\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3729 - accuracy: 0.8306 - val_loss: 0.3919 - val_accuracy: 0.8361\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3744 - accuracy: 0.8264 - val_loss: 0.3898 - val_accuracy: 0.8361\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8512 - val_loss: 0.3892 - val_accuracy: 0.8361\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3313 - accuracy: 0.8347 - val_loss: 0.3880 - val_accuracy: 0.8361\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3634 - accuracy: 0.8347 - val_loss: 0.3872 - val_accuracy: 0.8361\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3568 - accuracy: 0.8099 - val_loss: 0.3869 - val_accuracy: 0.8361\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3752 - accuracy: 0.8182 - val_loss: 0.3874 - val_accuracy: 0.8361\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3394 - accuracy: 0.8760 - val_loss: 0.3879 - val_accuracy: 0.8361\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3522 - accuracy: 0.8636 - val_loss: 0.3885 - val_accuracy: 0.8361\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3361 - accuracy: 0.8223 - val_loss: 0.3892 - val_accuracy: 0.8361\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3227 - accuracy: 0.8430 - val_loss: 0.3894 - val_accuracy: 0.8197\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8388 - val_loss: 0.3894 - val_accuracy: 0.8197\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3515 - accuracy: 0.8264 - val_loss: 0.3900 - val_accuracy: 0.8197\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3290 - accuracy: 0.8306 - val_loss: 0.3902 - val_accuracy: 0.8197\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3170 - accuracy: 0.8554 - val_loss: 0.3908 - val_accuracy: 0.8033\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2854 - accuracy: 0.8926 - val_loss: 0.3919 - val_accuracy: 0.8033\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3104 - accuracy: 0.8719 - val_loss: 0.3930 - val_accuracy: 0.8033\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3050 - accuracy: 0.8719 - val_loss: 0.3932 - val_accuracy: 0.8033\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3081 - accuracy: 0.8678 - val_loss: 0.3925 - val_accuracy: 0.8033\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.8719 - val_loss: 0.3929 - val_accuracy: 0.8033\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3231 - accuracy: 0.8595 - val_loss: 0.3936 - val_accuracy: 0.8033\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.8554 - val_loss: 0.3937 - val_accuracy: 0.8033\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2905 - accuracy: 0.8843 - val_loss: 0.3934 - val_accuracy: 0.8033\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2967 - accuracy: 0.8595 - val_loss: 0.3947 - val_accuracy: 0.8033\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3074 - accuracy: 0.8678 - val_loss: 0.3963 - val_accuracy: 0.7869\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2611 - accuracy: 0.8884 - val_loss: 0.3974 - val_accuracy: 0.7869\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2966 - accuracy: 0.8719 - val_loss: 0.3985 - val_accuracy: 0.7869\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2710 - accuracy: 0.8884 - val_loss: 0.3986 - val_accuracy: 0.7869\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2648 - accuracy: 0.8678 - val_loss: 0.3987 - val_accuracy: 0.7869\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2663 - accuracy: 0.8967 - val_loss: 0.3999 - val_accuracy: 0.7869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1582e762f40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7fd6eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 675ms/step\n",
      "This particular patient had a 26.3 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    \"age\": 60,\n",
    "    \"sex\": 1,\n",
    "    \"cp\": 1,\n",
    "    \"trestbps\": 145,\n",
    "    \"chol\": 233,\n",
    "    \"fbs\": 1,\n",
    "    \"restecg\": 2,\n",
    "    \"thalach\": 150,\n",
    "    \"exang\": 0,\n",
    "    \"oldpeak\": 2.3,\n",
    "    \"slope\": 3,\n",
    "    \"ca\": 0,\n",
    "    \"thal\": \"fixed\",\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = model.predict(input_dict)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c1eed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
